# -*- coding: utf-8 -*-
"""Heart_Disease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dEyhQ9D13hjhlFXHyEnYWFGb8WK3odJP
"""

pip install --upgrade pandas

#Importing Important Libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,classification_report,roc_curve
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_graphviz
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import GridSearchCV
import matplotlib.pyplot as plt
import seaborn as sns
import os

#Loading dataset
df=pd.read_csv('/content/heart-disease (1).csv')
df.describe()

catf = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall']
conf = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']

# Data Exploration
df.isna().sum()

#Correlation between the features
plt.figure(figsize=(18, 5))
heatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True)
heatmap.set_title('Features correlation Heatmap', fontdict={'fontsize':5}, pad=5)

#Data Visualization
# Another visualization of pairwise relationships in our dataset
sns.pairplot(df,hue='thal')
plt.show()

#Creation of labels
label = df['target']
data = df.drop('target', axis = 1)

#Preparing Model
x_train, x_test, y_train, y_test = train_test_split(df,label,test_size = 0.2, random_state = 56)
print("Shape of x_train :", x_train.shape)
print("Shape of x_test :", x_test.shape)
print("Shape of y_train :", y_train.shape)
print("Shape of y_test :", y_test.shape)

#Running model
model = RandomForestClassifier(max_depth = 5)
model.fit(x_train, y_train)
y_predict = model.predict(x_test)
y_pred_quant = model.predict_proba(x_test)[:, 1]
y_pred = model.predict(x_test)

#Data Evaluation
#Accuracy
print("Training Accuracy :", model.score(x_train, y_train))
print("Testing Accuracy :", model.score(x_test, y_test))

#Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.rcParams['figure.figsize'] = (5, 5)
sns.heatmap(cm, annot = True, annot_kws = {'size':15}, cmap = 'PuBu')
plt.title('Confusion Matrix for Decision Tree Model', y = 1.1)
plt.ylabel('Actual Label')
plt.xlabel('Predicted Label')
plt.show()

#Classification Report
cr = classification_report(y_test, y_pred)
print(cr)

#Feature Engineering
data_f = df
# Binning continuous features
# age
data_f['age'] = pd.cut(x=data_f['age'], bins=5)
# trtbps
data_f['trestbps'] = pd.cut(x=data_f['trestbps'], bins=5)
# chol
data_f['chol'] = pd.cut(x=data_f['chol'], bins=5)
# thalachh
data_f['thalach'] = pd.cut(x=data_f['thalach'], bins=5)

X = df.drop(['target'],axis=1)
y = df[['target']]

# Scaling continuous features
scaler = RobustScaler()
X[conf] = scaler.fit_transform(X[conf])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)

# Logistic regression classifier
# With feature engineering
clf = LogisticRegression()
# train the classifier
clf.fit(X_train, y_train)
# calculating the probabilities
y_pred_proba = clf.predict_proba(X_test)
# finding the predicted valued
y_pred = np.argmax(y_pred_proba,axis=1)
# printing the test accuracy
print("The test accuracy score of Logistic Regression Classifier is ", accuracy_score(y_test, y_pred))

y_true = y_test
y_pred = clf.predict(X_test)
print(classification_report(y_true, y_pred))